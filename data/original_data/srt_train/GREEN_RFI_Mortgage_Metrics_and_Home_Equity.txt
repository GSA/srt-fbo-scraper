O
Comptroller of the Currency Administrator of National Banks Subject:

OCC 2000­16

OCC BULLETIN
Risk Modeling
Description:

Model Validation

TO:

Chief Executive Officers and Compliance Officers of All National Banks, Department and Division Heads, and All Examining Personnel

PURPOSE
This bulletin provides guidance to help financial institutions mitigate potential risks arising from reliance on computer-based financial models that are improperly validated or tested. The guidance outlines key model validation principles and the Office of the Comptroller of the Currency's (OCC) expectations for a sound model validation process. The expectations included in this bulletin supplement previously issued model validation guidance, generally found in the subject matter booklets of the Comptroller's Handbook or OCC Bulletins.

CONTENTS
Background ....................................................................................................................... 1 General Procedures for Model Validation ........................................................................ 2 Elements of Sound Validation Policy ................................................................... 3 Validating the Model Inputs Component.............................................................. 4 Validating the Model Processing Component ...................................................... 5 Model Reports (Management Information System) ............................................. 7 Summary of Supervisory Expectations Regarding Model Validation.............................. 8

BACKGROUND
Computer models are abstract representations of the various relationships among events and values in the real world. They are used in banking to estimate risk exposure, analyze various business strategies, and estimate fair values of financial instruments and acquisitions. Due to a better understanding of their potential enhancement to management information systems, and due to the ongoing reduction in the cost of computing power, models are playing a progressively more important role in the banking industry. The tools are now routinely used for credit scoring,

Date: May 30, 2000

Page 1 of 9

asset-liability management, trading-risk management, and for valuation estimates of financial instruments, such as securitization retained interests. In the next decade, it appears that the models will increasingly guide enterprise-wide risk management, economic, and regulatory capital allocation, whole-bank credit risk, fiduciary asset management, and internal profitability measurement. In light of this increasingly pervasive use, it is apparent that models can provide extremely useful information for bankers' decision making. Model development is a complex and error-prone process. While many completed models work as planned, some models contain fundamental errors. Moreover, the internal logic of most models is usually very abstract and limiting, so it requires considerable judgment and expertise to apply model results outside of the narrow context under which they are derived. The OCC has observed several instances in which decision makers either relied on erroneous price or exposure estimates, or on an overly broad interpretation of model results, with serious consequences for their bank's reputation and profitability. There are many more instances in which the incorrect use of models created the potential for large losses, which were avoided only fortuitously. This problem is generally referred to as "model risk." Fortunately, model risk can be considerably reduced. Sound model building includes rigorous procedures for "model validation." Model validation not only increases the reliability of a model, but also promotes improvements and a clearer understanding of a model's strengths and weaknesses among management and user groups. A model consists of three components: An information input component, which delivers assumptions and data to the model; a processing component, which contains the theoretical model, transforms inputs into estimates via the computer instructions (code); and a reporting component, which translates the mathematical estimates into useful business information. Since errors in any of these three components can cause the model's information to be meaningless or misleading, an effective model-validation process must address all three components. In this document we delineate principles and policies that guide effective model-validation procedures and offer some specific examples. However, in practice, model validation requires not only technical expertise but also considerable subjective business judgment. It is important for decision makers to recognize that this subjectivity elevates the need for sound and comprehensive validation processes.

GENERAL PROCEDURES FOR MODEL VALIDATION
There are three generic procedures that are applicable when validating a model: (a) independent review of the logical and conceptual soundness, (b) comparison against other models, and (c) comparison of model predictions against subsequent real-world events. Depending on the circumstances, any or all of these procedures should be separately applied to each of a model's three components. Regardless of a bank's size, the OCC believes that it is essential that banks develop formal policies that ensure that all of these principles are applied when circumstances warrant. The depth and extent of the validation should be consistent with the materiality and

Date: May 30, 2000

Page 2 of 9

complexity of the risk being managed. If properly designed, formal validation policies provide staff with the necessary guidance as to the rigor desired by decision makers, who in turn can be confident that the bank's modeling information is reliable and useful within the given business context, and is delivered at reasonable cost. Elements of Sound Validation Policy A bank's validation policy should help ensure that its model-validation efforts are consistent with senior management's view of the proper trade-off between costs and benefits. To reflect that view, the policy should include the following elements: Independent Review The personnel performing model validation should be as independent as possible from the personnel who construct the model. At money-center banks, with multiple modeling "shops," independent review is often readily available in house, and can be complemented by external reviewers or internal audit. For smaller banks, the validation policy should provide for as independent a review as practicable. When comprehensive independence is not practicable, the policy should explicitly provide for an effective communication process between modelers and decision makers; technical complexity never liberates model builders from the responsibility for providing clear and informative descriptions of modeling assumptions and limitations to senior management. Defined Responsibility The responsibility for model validation should be formalized and defined just as is the responsibility for model construction. Consistent with best practices, policies should specify that, before a model can enter production, (a) the independent model-validation unit or external reviewer must document the model validation tests and the reasons for concluding that the model is valid, and (b) internal audit must verify that no models enter production without formal approval by the validation unit. At smaller banks that lack the resources for effective independent review, the policy should explictly require senior management to formally approve all models that are used for pricing or risk-limit compliance. Management should approve both the conceptual approach and the key assumptions for such models, and verify that reasonable quality-control processes are in place. Model Documentation Model documentation creates a corporate memory in the event of the departure of key modeling personnel. At the corporate-wide level, a catalogue of models and their applications should be maintained. Policy should also require documentation for specific models that is adequate to facilitate independent review, training of new staff, and clear thinking by the model developer. The most rigorous policies require documentation that is sufficiently detailed to allow the precise replication of the model being described. At a minimum, model documentation should provide summary overviews of the general procedures used and the reasons for choosing those

Date: May 30, 2000

Page 3 of 9

procedures, describe model applications and limitations, identify key personnel and milestone dates in model construction, and describe validation procedures and results. Ongoing Validation Even after entering production, most models are frequently altered in response to changes in the environment or to incorporate improvements in modelers' understanding of the model's subject. However, model alterations can also help evade risk limits or disguise losses. For example, modest changes in the assumptions that quantify future interest-rate volatility can significantly reduce a model's estimate of a bank's interest-rate exposure, or increase the estimated value of a position in interest-rate derivatives. Such changes will generally be obscure to senior management, but can hide noncompliance with interest-rate-risk limits or trading losses. Best practices for validation policies require that all changes in the modeling process be documented and submitted for independent review. A useful practice is to allow model changes only periodically, and only after independent review and approval by the appropriate level of the bank's decision makers. It is useful for a bank to store multiple copies of model code to facilitate disaster recovery, as well as to monitor assumption changes. Models should be subjected to change-control procedures, so that code cannot be altered except by approved parties. Audit Oversight While large banks may have model-validation units with internal audit departments, model validation is often outside the scope of audit responsibilities. Nevertheless, the formal policy should clearly specify that internal audit is responsible for ensuring that the model validation and model-validation units adhere to the formal policy. Validating the Model Inputs Component Data It is possible that data inputs contain major errors while the other components of the model are error free. When this occurs, the model outputs become useless, but even an otherwise sound validation process will not necessarily reveal the errors. Hence, auditing of the data inputs is an indispensable and separate element of a sound model-validation process, and should be explicitly included in the bank's policy. Data come from both internal sources and external sources. For data arising from internal sources, the bank's audit functions should ensure that information provided to the model agrees with the bank's general ledger data, terms of outstanding contracts, and so on. Externally provided data can also often be checked against multiple sources. In addition, extremely effective and inexpensive procedures to spot errors include automated filters and the inspection of the inputs by experienced personnel.

Date: May 30, 2000

Page 4 of 9

In some cases, particularly when models are relatively new, it is difficult for the responsible business units to ensure that the data inputs are always accurate. If a bank decides that the model provides useful information despite the data problems, the bank's policies should specify that audit, risk management, and modeling personnel are independently responsible for apprising senior management of the data problems. This alerts decision makers both that the model results may not be completely reliable and that there may be a need to devote more resources to providing quality data. Assumptions Besides raw data, computer models require an array of assumptions. Prime examples include prepayment functions for loan-valuation models, "market-implied" interest-rate volatilities for derivative pricing models, and core-deposit decay assumptions for asset-liability models. These types of assumptions are generally determined by a separate model, which itself has inputs, processing and outputs that should be validated using the principles elucidated here. Many assumptions will be available in general form from publicly available sources at relatively low cost. For example, many banks use the market-implied volatilities and mortgage prepayments that are available from the various vendors. On the other hand, a bank may feel that it is better to derive its assumptions by studying its own customer base than by using general information about national or regional populations. Similarly, a bank may feel that it has a special insight into market behavior, and that its assumptions about markets are superior to publicly available assumptions. Modelers should be able to provide a clear rationale for their choice between public and private assumptions. Whether drawn from public sources or from the bank's own research, important behavioral assumptions should be routinely compared to actual portfolio behaviors. For example, prepayment assumptions project the actual prepayment rates for "all possible" changes in interest rates. These projections should be compared, on a monthly basis, to the actual prepayment behavior that the bank experiences on its residential mortgage loan and security portfolios. As interest rates change, the bank's actual prepayment rates will change. If, over a period of several months, actual changes are consistently more pronounced than projected, then the prepayment function is systematically over optimistic (and the converse holds as well). As a best practice, some banks routinely include these comparisons in the reports to senior management. Validating the Model-Processing Component Model processing consists of the computer code and the theoretical models that the code implements. The choice of theory is at least partly a matter of art rather than science: all theories are greatly simplified representations of reality, and judgment comes into play in deciding what simplifications are acceptable. Aside from the choice of theory, the validation policies for the processing component of its models should ensure that the mathematics and computer code are error free.

Date: May 30, 2000

Page 5 of 9

Code and Mathematics A number of procedures exist for testing code. Most models, such as those that operate in spreadsheets, have relatively simple code and equations, which can be cheaply tested by the independent construction of an identical model. If the results of the two models agree precisely, it is usually highly unlikely that the two independently constructed models would contain precisely identical errors. For more complex models, independent construction of an identical model may be too costly. These situations require alternative practices. Some practices will: (1) Assign a modeling professional with the task of line-by-line proofreading of the code. This practice may uncover most of the errors, but is not foolproof. (2) If possible, compare model results to the results from a second, well-validated "benchmark" model. This procedure is most useful when the validator can ensure that the inputs and theory in the second model are identical to those of the first, at least for a trial run. In most cases, however, the inputs and theory will differ at least slightly between the two models, so there will be at least slight discrepancies between the model outputs. Unless the discrepancies are glaring, the validator will be required to render a subjective judgment of whether the output differences are the result of input differences or processing error in the model under construction. Even if a bank uses a vendor model, it should seek assurances that the model is defensible and works as promised. Vendor models present banks with a trade-off between convenience and transparency. Within the limit that vendors will not reveal proprietary information, bank users of vendor models should require that the vendors provide information on how the vendor built and validated the model. As professional modelers, vendors should themselves follow good model validation practices and demonstrate that to client banks. One common misconception is that validation of the computer processing is not necessary for vendor models, because these models have "met the market test." In fact, banks that apply good validation procedures to vendor models often find material processing errors. These experiences illustrate that the same validation principles should be applied regardless of whether a model is purchased from a vendor or developed in house. When evaluating vendor models, banks should consider the ease with which, once identified, processing and other software errors can be corrected. Theory Implementing a computer model usually requires the modeler to resolve several questions in statistical and economic theory. Generally, the answer to those theoretical questions is a matter of judgment, though the theoretical implementation is also prone to conceptual and logical error. An obvious means to guard against this source of model error is to ensure that the theorist has the training and experience necessary to perform the work. One of the largest sources of model error arises in the use of theoretical tools, most often statistical methods, by untrained modelers.

Date: May 30, 2000

Page 6 of 9

Regardless of the qualifications of the model developers, an essential element of model validation is independent review of the theory that the bank uses. In many circumstances, internal review will be quite effective. In other circumstances, effective internal review is difficult to obtain. In those situations, senior management should expect modelers to (a) provide clear descriptions, in nontechnical terms, of the theory underlying the models; and (b) show that the theory underlying the model has received recognition and support from professional journals or other forums. Comparison to other models is often very useful for uncovering theoretical errors. In this case, other models include pre-existing or similar models already in use at the bank, market prices (which represent the "True Model"), and publicly available model results. When developing a new model, the comparison of the results to these other sources of information will confirm the modeler's expectations, reveal a model error, or lead to an enhanced understanding of the phenomenon under scrutiny. Model Reports (Management Information Systems) After processing the inputs, the model produces price or exposure estimates, or decision indices that will be used by decision makers. Obviously, the model validation process should assess the validity of those estimates. However, it is equally important that the reports distilled from model output are clear and that decision makers understand the context in which the model results are generated. Validating Model Results Many of the procedures used to validate the input and processing components of a model are also useful for validating the model results. At the time a model begins to produce outputs, model developers and validators should compare its results against those of comparable models, market prices, or other available benchmarks. Once in use, model estimates should continually be compared to actual results, a procedure referred to as "back testing," "out-of-sample testing," and similar terms. Many models, assetliability models in particular, deliver projections that are "conditional" upon the economic environment that actually materializes; over time, such conditional projections can also be validated against actual outcomes. Validating the Context of Reports The business decision maker and the modeler often have quite different backgrounds. Even in apparently clear pricing and risk reports, the modeler and the decision maker may interpret the information in quite different ways. For example, decision makers often mistake a model's risk estimates as the "worst-case scenario" for their banks, even though there are inevitably plausible scenarios and assumptions under which the bank could lose more than estimated. When addressing model-documentation requirements, a bank's model-documentation policy should include the requirement for an executive summary that is made available to senior

Date: May 30, 2000

Page 7 of 9

management. Properly explained, the questions that models answer are invariably quite narrow in strict logical terms, so a clear statement of model purposes helps senior decision makers understand the limitations of the model. The summary should also include the major assumptions, further illuminating the model's limitations. Independent review of a model's underlying theory should always extend to the reports that transmit information from the modeler to the decision maker. An essential element of designing a model's reports is ensuring that the results are communicated clearly and accessibly. In addition to the model estimates used to estimate fair values or assess risk, best-practice model reports also contain sensitivity analyses, or so-called "what if" scenarios. These provide alternative estimates using reasonable alternatives for the major assumptions. Sensitivity analysis serves not only to provide a range of estimates, but to communicate to decision makers the robustness or fragility of outputs from the model.

SUMMARY OF SUPERVISORY EXPECTATIONS REGARDING MODEL VALIDATION Model validation can be costly, particularly for smaller banks. On the other hand, using unvalidated models to manage risks to the bank is potentially an unsafe and unsound practice. Even where the risk is not particularly material, the reliance on unvalidated models can be a poor business practice. Supervisors believe that the assessment of the costs and benefits of model validation is subjective and context-driven and is the responsibility of senior management. To promote a sound process, the OCC expects that formal policies ensure the following goals are met: (a) Decision-makers understand the meaning and limitations of a model's results. Where the models are too abstract for non-specialists to understand the underlying theory, the bank must have a model reporting system in place that transforms the models' outputs into useful decision-making information without disguising the model's inevitable limitations. (b) Particularly when a model has been in use for a reasonable period of time, its results are tested against actual outcomes. (c) The bank should demonstrate a reasonable effort to audit the information inputs to the model. Input errors should be addressed in a timely fashion. (d) The seniority of the management overseeing the modeling process should be commensurate with the materiality of the risk from the line of business in process. (e) To the extent feasible, model validation must be independent from model construction. (f) Responsibilities for the various elements of the model-validation process must be clearly defined.

Date: May 30, 2000

Page 8 of 9

(g) Modeling software should be subject to change-control procedures, so that developers and users do not have the ability to change code without review and approval by an independent party. Computer models are increasingly used in banking to estimate risk exposure, analyze business strategies and estimate fair values of financial instruments and acquisitions. As models play an increasingly important role in decision-making processes, it is critical that bank management reduce the likelihood of erroneous model output or incorrect interpretation of model results. The best defense against such "model risk" is the implementation of a sound model validation framework that includes a robust validation policy and appropriate independent review. If you have any questions on the contents of this bulletin, please contact either the Risk Analysis Division at (202) 874-5250 or the Treasury and Market Risk Division at (202) 874-5670.

_________________________________ Jeffrey A. Brown Director, Risk Analysis Division

__________________________________ Kathryn E. Dick Director, Treasury and Market Risk Division

Date: May 30, 2000

Page 9 of 9

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics Request for Information
10/5/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

PURPOSE The Office of the Comptroller of the Currency (OCC) is seeking input from industry to assist its Large Banks Supervision (LBS) Division in preparation for the acquisition of services to support its data collection, validation, storage and analytical reporting and query requirements.

THE GOVERNMENT DOES NOT INTEND TO AWARD A CONTRACT ON THE BASIS OF THIS RFI OR REIMBURSE ANY COSTS ASSOCIATED WITH THE PREPARATION OF RESPONSES TO THIS RFI. This RFI is issued solely for information and planning purposes and does not constitute a solicitation. All information received in response to this RFI marked Proprietary will be handled accordingly. Responses to the RFI will not be returned.

BACKGROUND

The Office of the Comptroller of the Currency (OCC) charters, regulates, and supervises all United States national banks. OCC also supervises the federal branches and agencies of foreign banks. Headquartered in Washington, D.C., the OCC has four district offices plus an office in London to supervise the international activities of national banks. Bank supervision is the core activity of the agency; bank examiners comprise the majority of the approximately 2,800 employees. The OCC was established in 1863 as a bureau of the U.S. Department of the Treasury. The Comptroller is the chief executive of the OCC. The President appoints the Comptroller for a five-year term with the advice and consent of the Senate. The Comptroller also serves as a director of the Federal Deposit Insurance Corporation (FDIC) and a director of the Neighborhood Reinvestment Corporation.
Page 2 10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

The OCC's nationwide staff of examiners conducts on-site reviews of national banks and provides sustained supervision of bank operations. The agency issues rules, legal interpretations, and corporate decisions concerning banking, bank investments, bank community development activities, and other aspects of bank operations. SCOPE Comprehensive mortgage and home equity data is vital to assessing and monitoring credit quality and loss mitigation activities in the residential mortgage market and the national banking system. This data is important and necessary to support supervisory activities to ensure the safety and soundness of the national banking system. OCC is requesting information from organizations who demonstrate the capacity and capability to collect, validate, store and perform analytical querying and reporting on comprehensive datasets. OCC currently collects comprehensive Mortgage and Home Equity from (9) of the largest national banks based on standard data and definitions on a monthly basis. The Mortgage data collected comprises of approximately 64% of all mortgages outstanding in the United States and consists of 34 million 1st lien residential mortgages across 104 loan level data elements and 14 loan level property elements. The Home Equity data collected comprises of approximately 60% of all the loans and lines of credit in the United States and consists of approximately 10 million Junior Liens and Lines of Credit metrics across 76 loan level data elements and 16 Portfolio level data elements, as well as 14 loan level property elements. The OCC also intends to expand the data collection process to include Mortgage origination data which will consist of approximately 45 loan level elements. This data will be collected from (9) of the largest national banks based on standard data and definitions on a monthly basis. Several key objectives have been identified below to support the data and analytical needs of the OCC for both current and expanded datasets. The objectives provide the high-level details in which the respondents to this request

Page 3

10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

for information must present knowledge and demonstrate the analytical capability to provide services pertaining to all objectives defined below. Objectives must be achieved within 30 days of project inception to ensure business continuity. KEY OBJECTIVES The response to this RFI should focus on meeting the following objectives: 1. Comprehensive Data Collection All data collected will be based on standard data and definitions. All data will be collected on a monthly basis (30 days after month-end) with the exception of the P&L data, which will be collected on a quarterly basis. The collection of the comprehensive data will include defining the data structure format in which the data will be collected based on the standard data elements and definitions as provided by the OCC. The data structure and collection process must support the collection of data files from single and or multiple disparate banking systems for each reporting entity. The collection process must be repeatable and institutionalized for each monthly and or quarterly collection cycle and must provide the ability to handle full and or partial resubmissions based on either current month and or historical metrics as required. The data collection structure and process must allow for additions, modifications and or deletions of data elements based on changes as defined by the OCC. The data collection process must incorporate the ability to process large data files based on the agreed upon format of the file (i.e. XML, Delimited File, etc...). The process must include standard protocols and contingency planning to ensure that back up processes, systems and procedures are in place to handle and collect this high volume of data to meet OCC timeframes. The organization must demonstrate experience and knowledge on data collection technologies, as well as data process automation, to ensure
Page 4 10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

data is collected and processed in the most efficient and effective manner to meet OCC timeframes as stated within the objectives. 2. Data Validation, Verification and Quality Assurance Data validation and verification must be automated and performed against each data submission, source file and loan level record received. Standard edit checks and validations must be applied during each submission cycle, including files based on resubmissions that are received outside the normal processing cycle. Validation and verification reports and metrics are required based on the data validation and verification edit checks implemented. Validation and Verification reports must be provided within (3) business days after receipt of the data file(s) from the reporting entities. Validation and verification reports will include but not limited to the following: Compliance with the data definitions, structure and format; Mandatory Field Requirements compliance; Quality and logical scenarios; Field data distribution including counts and percentages for current and subsequent submission periods; 5. Edit failures and distribution of values for loan level files including data not provided and or not available per each reporter and in aggregate; 6. Data trend report to identify and track improvements; 7. Data quality benchmarking metrics for reporting institution comparisons. The data validation and verification process must be a repeatable and automated institutionalized process within the organization. The validation process must include a quality assurance review of data submissions to ensure accuracy and validity of data. The process must provide the ability to add, modify and or remove validation and verification 1. 2. 3. 4.

Page 5

10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

checks on an as needed basis and provide the ability to execute on a historical and/or go-forward basis. All data must be validated and verified prior to delivering to the OCC. 3. Secure Data Transmission, Storage and Technology Infrastructure The contractor must possess the ability to provide and ensure that solutions, services, facilities, and products provide appropriate safeguards for confidentiality and integrity. All security controls must be in full compliance with all applicable Federal regulations and statutes governing information technology, privacy, and security. Organization will need to provide comprehensive Continuity of Operations (COOP) and disaster recovery provisions to ensure system security and availability, as well as to ensure acceptable performance can be achieved when utilizing data encryption. All data artifacts must be accessible using a secure technology. The OCC, reporting entities and the respondents will utilize this technology for data and file sharing. The technology must support role-based security and provide a dashboard capability to structure the data artifacts for use. The contractor will be responsible for hosting and supporting the technology as well as supporting reporting entities and the OCC with any setup and configuration if needed. 4. Analytical Tools - Online Query and Reporting Secure online query and reporting tool(s) are required utilizing either a third party or proprietary software package. System requirements will be provided by the OCC and reviewed and finalized prior to system development. A change control process will be implemented to capture new requirements and system changes to query and reporting systems. Systems should provide real-time access to fully validated and verified data on a monthly basis and provide access and query and reporting capability on each data element collected across all months.
Page 6 10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

The query tool must be accessible utilizing a secure technology and include, but not be limited to, the following high level functional requirements: 1. Provide access to fully validated and verified data within (10) business days after receipt of the data files; 2. Search by all data elements collected; 3. Filter results based on user defined filter; 4. Incorporate logical scenario measures and derivations; 5. Save user defined queries for access and use by other users; 6. Create, Update, and Delete user defined queries; 7. Export query and data results in Microsoft 2003 or greater formats; 8. Query access to data collected for all months; 9. Enhanced analytical capabilities including benchmarking and peer analysis and comparison of metrics; 10. Admin module for OCC personnel to assign access and management users of the system; 11. Provide optimum performance in querying large data sets and meet the performance standards as identified by the OCC. Standardized reports will need to be developed based on OCC requirements. OCC currently has several reports that are currently in use that will need to be built into the proposed technology based on the data elements currently available. Standardized reports will include Congressional mandated reports in which must be implemented and delivered within (30) days from inception of the project and will be required on quarterly basis. OCC reserves the right to require up to (30) standardized reports for each data set collected. Reports will need to support all data collected from single or multiple reporting sources from the reporting institutions. Standardized reports must be accessible utilizing a secure technology and include, but not be limited to, the following high level functional requirements:

Page 7

10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

1. Provide access to standardized (10) business days after receipt of the data files; 2. Developed based on OCC formatting and presentation requirements; 3. Execute reports based on predefined filters and or reporting parameters based on OCC requirements and data elements; 4. Export reports in MS Excel 2003 or greater and PDF formats; 5. Enhanced security with role and report-level-based security; 6. Ability to filter and find specified data within a given report; 7. Admin module for OCC personnel to assign access and manage users of the system; 8. Access to data collected for all periods Query and reporting technology should support unlimited number of users and support up to 50 concurrent users with no deterioration of system performance. 5. Ad Hoc Data Extracts The contractor will be responsible for executing ad hoc data requests within (1) business day from request. Full data extracts will also be required of both source file and loan level fully validated data. Extracts may also be requested based on loan level information, aggregate and /or logical scenarios as defined by the OCC. Data may be requested periodically or on a recurring basis. The contractor will be responsible for delivering extracts in a compatible file format (i.e. XML, delimitated file type, SAS format, etc...) and the delivery method for these extracts shall use a secure technology as defined in objective #3 above. The contractor may be responsible for performing ad hoc extracts of data pertaining to market research and/or ad hoc analysis that has been conducted by the contractor. 6. Resources

Page 8

10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

Contractor shall designate a qualified project manager for each data set and staff each data set with adequate and dedicated resources to meet OCC objectives and business requirements. 7. Technical and Analytical Support Direct technical and analytical support is required Monday through Friday 8am ­ 5pm EST. Responses to initial support calls are required within 24 hours. 8. Communication The contractor will be responsible for on-going communication with the OCC and reporting institutions. Contractor responsibilities will include but are not limited to the following: 1. Working with institutions to resolve any submissions or data quality issues; 2. Communicating changes, modification, or deletions to the data elements and definitions; 3. Notifying OCC and obtaining approval based on the data collection deficiencies or concerns; 4. Working with the reporting institutions to coordinate the collection of data from single or disparate systems; 5. Weekly status reports to the OCC based on work items performed, completed and issues requiring attention; 6. Documenting meeting summaries, issues and actions with the OCC and reporting institutions. 9. Property Valuation using AVM/HPI models The contractor must possess the capability to apply Automated Valuation Model (AVM) and or Home Price Index (HPI) methodology to collected and existing 1st lien Mortgage and 2nd lien Home Equity data. The Contractor will utilize the AVM and or HPI methodology to derive and obtain refreshed property values for each loan using the property address
Page 9 10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

data elements collected in each monthly submission on a quarterly basis. Contractor AVMs must be validated in accordance with model validation standards contained in OCC Bulletin 2000-16. The contractor must apply a data validation methodology to the collected property address values to determine validity and return any invalid property address files to the reporting institution for correction. The contractor will be responsible for mapping 1st lien and 2nd lien property address data based on property address values collected on a monthly basis. The contractor will be responsible for developing and delivering monthly reports quantifying the number of invalid, unmatched and successfully matched loans. Standardized extracts and reports will be developed based on the matched property address data and logical defined scenarios. All collected and formulated data (including refreshed values) should be accessible via on-demand data extracts and a Web-based delivery method. Both methods of delivery must be acceptable to OCC and meet federal security requirements and comply with Section 508 of the Rehabilitation Act of 1973. 10. Relationship with Institution and business line expertise Existing business relationships with national banks and knowledge of the national banking system will be required. Additionally, strong subject matter expertise in the areas of mortgage and home equity lending and processing are required.

The OCC intends to grant the reporting national banks with timely access to their own confidential data and market data generated by the contractor that incorporates OCC confidential data. Disclosure of OCC confidential data to a third party without the OCC's permission will be prohibited.

11. User Acceptance Testing and Training
Page 10 10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

The contractor will be responsible for providing a test environment to the OCC to perform user acceptance testing activities prior to training and production software and data releases.

The contractor will be responsible for training OCC approved users on the systems and technology, including the secure online query, reporting and dashboard technologies. The contractor will be responsible for developing the training materials and artifacts including a training reference guide, user's manual, sample case scenarios and quick start guide, as well as providing desk side coaching and technical assistance during the training sessions.

Training session will take place at OCC Training Centers located in Chicago, IL; New York, NY; Dallas, TX; or Washington, DC and will occur on a quarterly basis.

12. Documentation The contractor will be responsible for documenting all business and technical aspects of the data collection process. Documentation will include but not limited to the following: 1. Data Collection process and various actors and actions within each work stream; 2. Database design and entity relationship diagram; 3. Logical and coding scenarios used for reports and derived values/analysis; 4. Edit and data validation procedures as well as scripts used; 5. System and environment architecture. 13. Accessibility

Page 11

10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

All deliverables are required to be accessible by individuals with disabilities. OCC is required to comply with Section 508 of the Rehabilitation Act of 1973, as amended and support OCC Equal Opportunity (EEO) policy which defines the OCC workforce to include individuals with disabilities. 14. Consistently Apply Industry-leading Quality Management Practices across the Entire Range of Services. The contractor will be responsible for providing a service delivery model to ensure that service availability and delivery meet business requirements and expectations. The contractor should identify and assess methods to streamline processes and continuously improve service levels with the reporting national banks and the OCC. 15. Manage Risk. The contractor must have proven right-sized, supportable, and sustainable technology solutions. The contractor must have standardized processes such as change management, configuration management and standard operating procedures (SOPs) to efficiently minimize risk within the organization. The contractor must employ knowledge management practices to retain institutional knowledge and ensure continuity of services.

Page 12

10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

ACQUISITION STRATEGY Based on responses received to this RFI, OCC may elect to issue a Statement of Objectives (SOO) detailing the services for which OCC will solicit proposals. The SOO will provide a comprehensive, disciplined, performance-based approach to meeting the OCC requirements. The intention of using a SOO instead of a conventional performance-based work statement (PWS) is to provide the maximum flexibility to each Offeror to propose innovative solutions using proven processes, methods, standards and technologies. SUBMISSION INSTRUCTIONS Responses to this RFI should be in the form of a White Paper not-to-exceed 15 single-spaced pages. In providing responses to the objectives, questions and key focus areas identified herein, all submissions shall conform to the following format: Recommended Approach (10 pages) ˇ Summary of the recommended approach or approaches, if more than one alternative is described ˇ High-level (5-10 steps) project plan to effect the approach and the ability to achieve a production-ready operation within (45) days after project inception. ˇ Major risks of the recommended approach ˇ Emerging technologies that might either obsolete or complement the approach in the future ˇ Summary of strategies to mitigate risks Corporate Information (5 pages) ˇ Capabilities (product vendor, integrator, etc.) ˇ Relevant experience with the technologies recommended ˇ Relevant experience with data analytics efforts ˇ Relevant experience with the federal government and financial industry No reimbursement will be made for any costs associated with providing information in response to this RFI or any follow-up information requests.

Page 13

10/13/2010

Office of the Comptroller of the Currency
Mortgage and Home Equity Data Collection, Validation, Storage and Reporting Analytics RFI

The Government welcomes any information submitted by interested parties in response to this request and encourages participation from both large and small businesses. Comments, whether supportive or critical, are earnestly solicited regarding every aspect of the proposed initiative. The Government will not critique any information that a potential offeror provides. The Government reserves the right to reject, in whole or in part, any industry input as a result of this announcement. A responding organization may describe more than one solution or approach; however, if more than one solution or approach is presented the submission should clearly separate them. Although not responding to this RFI may result in the Government being unable to adequately assess the market place, eligibility to participate in a future acquisition is not predicated on a response to this RFI. The Government welcomes any questions responding organizations may have regarding this RFI. Questions should be submitted via email to Andrea Katz, Contract Specialist, at Andrea.Katz@occ.treas.gov no later than 4:00 P.M. EDT on October 18, 2010. The Government's response to substantive questions may be made in writing and available as an addendum to this RFI. All questions and inquiries relating to this notice must be submitted via e-mail. DISCLAIMER This RFI is for planning purposes only and shall not be construed as a Request for Proposals (RFP), Invitation for Bid (IFB) or as an obligation on the part of the Government to acquire any services. Responses to this RFI shall not serve as proposals, bids, or offers. In accordance with FAR 15.201(e), responses to this RFI are not offers and cannot be accepted by the Government to form a binding contract. The Government reserves the right to determine how it should proceed as a result of this notice.

Page 14

10/13/2010

