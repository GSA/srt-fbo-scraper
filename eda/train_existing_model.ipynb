{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "import dill as pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Statement of Need\\n1. Purpose: Addition of SSD...</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REVISION: 2\\n\\n*HISTORY*\\n\\nENGINEERING DATA L...</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>406 SCMS/GULAA-Hill\\n\\nOctober 1, 2015\\n\\nStat...</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MANUFACTURING QUALIFICATION REQUIREMENTS\\n6685...</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U.S Department of State (DOS)\\n\\nBureau of Int...</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Statement of Need\\n1. Purpose: Addition of SSD...   RED\n",
       "1  REVISION: 2\\n\\n*HISTORY*\\n\\nENGINEERING DATA L...   RED\n",
       "2  406 SCMS/GULAA-Hill\\n\\nOctober 1, 2015\\n\\nStat...   RED\n",
       "3  MANUFACTURING QUALIFICATION REQUIREMENTS\\n6685...   RED\n",
       "4  U.S Department of State (DOS)\\n\\nBureau of Int...   RED"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labeled_df = pd.read_csv('../data/fy23_training_labels.csv')\n",
    "labeled_df = pd.read_csv('../data/fy22_23_training_labels.csv')\n",
    "\n",
    "labeled_df.rename(columns={'attachment': 'text', 'label': 'label'}, inplace=True)\n",
    "labeled_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode labels to numeric, making the minority Green class the positive class\n",
    "labeled_df['target'] = labeled_df['label'].map({'GREEN':1,'YELLOW':0,'RED':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      92963\n",
       "mean       48610\n",
       "std        86216\n",
       "min            1\n",
       "25%         3696\n",
       "50%        10961\n",
       "75%        60302\n",
       "max      2334243\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describe the number of chars per text\n",
    "labeled_df['text'].apply(lambda x: len(x)).describe().apply(lambda x: '%.f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    92963\n",
       "mean      1631\n",
       "std       2045\n",
       "min          1\n",
       "25%        302\n",
       "50%        642\n",
       "75%       2416\n",
       "max      47722\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df['text'].apply(lambda x: len(set(x.split()))).describe().apply(lambda x: '%.f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/adambuckingham/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "no_nonsense_re = re.compile(r'^[a-zA-Z^508]+$')\n",
    "def strip_nonsense(doc):\n",
    "    \"\"\"\n",
    "    Returns stemmed lowercased alpha-only substrings from a string that are b/w 3 and 17 chars long. \n",
    "    It keeps the substring `508`.\n",
    "    \n",
    "    Parameters:\n",
    "        doc (str): the text of a single FBO document.\n",
    "        \n",
    "    Returns:\n",
    "        words (str): a string of space-delimited lower-case alpha-only words (except for `508`)\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = doc.lower()\n",
    "    doc = doc.split()\n",
    "    words = ''\n",
    "    for word in doc:\n",
    "        m = re.match(no_nonsense_re, word)\n",
    "        if m:\n",
    "            match = m.group()\n",
    "            if match in stop_words:\n",
    "                continue\n",
    "            else:\n",
    "                match_len = len(match)\n",
    "                if match_len <= 17 and match_len >= 3:\n",
    "                    porter = PorterStemmer()\n",
    "                    stemmed = porter.stem(match)\n",
    "                    words += stemmed + ' '\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes awhile, but is totally worth it\n",
    "labeled_df['normalized_text'] = labeled_df['text'].apply(strip_nonsense)\n",
    "\n",
    "labeled_df.to_pickle('fy22_fy23_normalized_training.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    92963\n",
       "mean       483\n",
       "std        491\n",
       "min          0\n",
       "25%        121\n",
       "50%        264\n",
       "75%        765\n",
       "max       5667\n",
       "Name: normalized_text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_df['normalized_text'].apply(lambda x: len(set(x.split()))).describe().apply(lambda x: '%.f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "model = pickle.load(open('../src/fbo_scraper/binaries/clf_ajbuckingham_roc_auc.pkl','rb'))\n",
    "\n",
    "labeled_df = pd.read_pickle('fy22_fy23_normalized_training.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92963, 92963)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "X = labeled_df['normalized_text']\n",
    "y = labeled_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y,\n",
    "                                                        stratify=y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=123)\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Fit model with new data\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         red       0.98      0.97      0.98       631\n",
      "       green       0.75      0.86      0.80        71\n",
      "\n",
      "    accuracy                           0.96       702\n",
      "   macro avg       0.87      0.91      0.89       702\n",
      "weighted avg       0.96      0.96      0.96       702\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adambuckingham/code/GSA/srt/srt-fbo-scraper/.venv_310/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/adambuckingham/code/GSA/srt/srt-fbo-scraper/.venv_310/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/adambuckingham/code/GSA/srt/srt-fbo-scraper/.venv_310/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/adambuckingham/code/GSA/srt/srt-fbo-scraper/.venv_310/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/adambuckingham/code/GSA/srt/srt-fbo-scraper/.venv_310/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/adambuckingham/code/GSA/srt/srt-fbo-scraper/.venv_310/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['red', 'green']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/adambuckingham/code/GSA/srt/srt-fbo-scraper/eda/train_existing_model.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/adambuckingham/code/GSA/srt/srt-fbo-scraper/eda/train_existing_model.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClassification Report:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/adambuckingham/code/GSA/srt/srt-fbo-scraper/eda/train_existing_model.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(metrics\u001b[39m.\u001b[39mclassification_report(y_train, y_train_pred, target_names\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mred\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "print(metrics.classification_report(y_train, y_train_pred, target_names=['red', 'green']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = 'clf_retrain_ajbuckingham_roc_auc'\n",
    "\n",
    "pickle_path = os.path.join(os.getcwd(),pickle_file+'.pkl')\n",
    "with open(pickle_path, 'wb') as f: \n",
    "    pickle.dump(model, f) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
